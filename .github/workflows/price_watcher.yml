name: Browser-Based Price Scraper
on:
  schedule:
    - cron: '0 0 * * 0' # Every Sunday
  workflow_dispatch:

jobs:
  scrape-prices:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install playwright supabase
          playwright install chromium
          playwright install-deps chromium

      - name: Run Playwright Bot
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python - <<EOF
          import os
          from playwright.sync_api import sync_playwright
          from supabase import create_client

          # 1. Setup Supabase
          supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))
          items = supabase.table("prices").select("*").eq("is_watched", True).execute().data
          print(f"Bot starting. Found {len(items)} items to scrape.")

          def scrape_walmart():
              with sync_playwright() as p:
                  # Use a real browser and a human-like User-Agent
                  browser = p.chromium.launch(headless=True)
                  context = browser.new_context(
                      user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
                  )
                  page = context.new_page()

                  for item in items:
                      url = item.get('external_url')
                      if not url or 'walmart.ca' not in url: continue
                      
                      try:
                          print(f"\nü§ñ Navigating to: {item['item_name']}...")
                          # Navigate to the product page
                          page.goto(url, wait_until="networkidle", timeout=60000)
                          
                          # Give the page a moment to resolve location/fulfillment
                          page.wait_for_timeout(5000)

                          # TARGET THE PRICE
                          # Walmart Canada typically uses data-testid="item-primary-price"
                          # We try multiple common selectors to be safe
                          price_selectors = [
                              '[data-testid="item-primary-price"]',
                              '[data-automation-id="atc-price-wrapper"]',
                              '.ld-unit-price',
                              'span[itemprop="price"]'
                          ]
                          
                          found_price = None
                          for selector in price_selectors:
                              element = page.query_selector(selector)
                              if element:
                                  found_price = element.inner_text()
                                  break

                          if found_price:
                              print(f"‚úÖ Found raw price: {found_price}")
                              # Clean string: "$12.97" -> 12.97
                              clean_price = float(found_price.replace('$', '').replace('current price', '').replace(',', '').strip())
                              
                              # Update Database
                              supabase.table("prices").update({
                                  "price": clean_price,
                                  "last_automated_update": "now()"
                              }).eq("id", item['id']).execute()
                              print(f"üöÄ Updated {item['item_name']} to ${clean_price} in DB.")
                          else:
                              print(f"‚ùå Failed to find price element for {item['item_name']}")

                      except Exception as e:
                          print(f"‚ö†Ô∏è Error scraping {item['item_name']}: {str(e)}")

                  browser.close()

          if __name__ == "__main__":
              scrape_walmart()
          EOF
