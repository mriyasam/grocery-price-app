name: Weekly Walmart Price Update
on:
  schedule:
    - cron: '0 0 * * 0' 
  workflow_dispatch:

jobs:
  update-prices:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Tools
        run: pip install requests supabase

      - name: Run Walmart Scraper
        env:
          SERPAPI_KEY: ${{ secrets.SERPAPI_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python - <<EOF
          import os
          import requests
          from supabase import create_client

          supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))
          
          # 1. Fetch only watched items
          items = supabase.table("prices").select("*").eq("is_watched", True).execute().data
          print(f"Checking {len(items)} watched items for Edmonton area...")

          for item in items:
              try:
                  url = item.get('external_url', '')
                  if not url or 'walmart.ca' not in url:
                      continue

                  # Extract ID (e.g., 6000188767373)
                  product_id = url.split('?')[0].rstrip('/').split('/')[-1]
                  
                  # Your localized targets
                  store_id = item.get('store_id') or "1187"
                  # This string tells SerpApi exactly where to 'be'
                  location_string = "T6X 1V3, Edmonton, Alberta, Canada"

                  print(f"\nðŸ“ TARGETING: {item['item_name']} in Edmonton (ID: {product_id})")

                  # ENGINE: walmart (Search)
                  # Searching for the ID directly is the best way to get a single match
                  params = {
                      "engine": "walmart",
                      "query": product_id,
                      "walmart_domain": "walmart.ca",
                      "location": location_string,
                      "store_id": store_id,
                      "api_key": os.getenv("SERPAPI_KEY")
                  }
                  
                  response = requests.get("https://serpapi.com/search", params=params).json()
                  
                  new_price = None
                  results = response.get('organic_results', [])

                  # Find the item in search results by matching ID in the link
                  for res in results:
                      if product_id in res.get('link', ''):
                          # Check primary_offer (Walmart Canada grocery standard)
                          new_price = res.get('primary_offer', {}).get('price') or res.get('price')
                          if new_price:
                              print(f"   âœ… Found Price: {new_price}")
                              break

                  # 2. SAVE IF FOUND
                  if new_price:
                      final_price = float(str(new_price).replace('$', '').replace(',', '').strip())
                      supabase.table("prices").update({
                          "price": final_price,
                          "last_automated_update": "now()"
                      }).eq("id", item['id']).execute()
                      print(f"âœ… UPDATED DATABASE: ${final_price}")
                  else:
                      print(f"âŒ NOT FOUND: Walmart Edmonton is not returning a price for this ID.")
                      if 'error' in response:
                          print(f"   API Note: {response['error']}")

              except Exception as e:
                  print(f"âš ï¸ ERROR: {str(e)}")
          EOF
