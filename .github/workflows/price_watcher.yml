name: Browser-Based Price Scraper (Walmart)
on:
  schedule:
    - cron: '0 0 * * 0' # Every Sunday
  workflow_dispatch:

jobs:
  scrape-prices:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install playwright supabase
          playwright install chromium
          playwright install-deps chromium

      - name: Run Playwright Bot
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python - <<EOF
          import os
          import re
          from playwright.sync_api import sync_playwright
          from supabase import create_client

          supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))
          
          # Fetch only items with a Walmart URL and is_watched = True
          items = supabase.table("prices").select("*").eq("is_watched", True).ilike("external_url", "%walmart.ca%").execute().data
          print(f"Bot starting. Checking {len(items)} Walmart items.")

          def run_bot():
              with sync_playwright() as p:
                  # Launch browser in a way that avoids bot detection
                  browser = p.chromium.launch(headless=True)
                  context = browser.new_context(
                      user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1",
                      viewport={'width': 375, 'height': 667} # Mimic a mobile device
                  )
                  page = context.new_page()

                  for item in items:
                      url = item.get('external_url')
                      if not url: continue
                      
                      try:
                          print(f"\nü§ñ Checking: {item['item_name']}...")
                          # Navigate to the FULL URL you provided
                          page.goto(url, wait_until="domcontentloaded", timeout=60000)
                          
                          # Wait for the price to appear (Walmart Canada uses this test ID)
                          page.wait_for_selector('[data-testid="item-primary-price"]', timeout=15000)
                          
                          # Get the price text
                          price_text = page.locator('[data-testid="item-primary-price"]').inner_text()
                          print(f"   Found text: {price_text}")

                          # Clean price (e.g. "$12.97" or "current price $12.97" -> 12.97)
                          # This regex finds the first number with a decimal
                          match = re.search(r"(\d+\.\d{2})", price_text.replace(',', ''))
                          if match:
                              new_price = float(match.group(1))
                              
                              # Update Database
                              supabase.table("prices").update({
                                  "price": new_price,
                                  "last_automated_update": "now()"
                              }).eq("id", item['id']).execute()
                              print(f"   ‚úÖ SUCCESS: Updated {item['item_name']} to ${new_price}")
                          else:
                              print(f"   ‚ùå Could not parse price from string: {price_text}")

                      except Exception as e:
                          print(f"   ‚ö†Ô∏è Error: Could not find price on page. (The item might be out of stock locally).")

                  browser.close()

          if __name__ == "__main__":
              run_bot()
          EOF
